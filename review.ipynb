{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cloud Characteristics</h3>\n",
    "<li>On-demand self-service</li>\n",
    "<li>Networked access</li>\n",
    "<li>Resource pooling</li>\n",
    "<li>Rapid elasticity</li>\n",
    "<li>Measured service</li>\n",
    "<h3>Challenge of earlier DS(networked) implementations</h3>\n",
    "<li>Complexity of implementations</li>\n",
    "<li>Vendor specific solutions</li>\n",
    "<li>Scale of the problem area</li>\n",
    "<h3></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture2: Domain Drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SWARM</h3>\n",
    "<li>Anonymous</li>\n",
    "<li>No leader</li>\n",
    "<li>Team size flexibility</li>\n",
    "<li>Public vs Private</li>\n",
    "<li>Arbitary contributions</li>\n",
    "<li>Social interactions</li>\n",
    "<li>ad hoc use encouraged</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture3: Overview of Distributed and Parallel Computing Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Computing Scaling</h3>\n",
    "<li>Vertical Computing Scaling</li>\n",
    "<ul>\n",
    "    <li>Have faster processors</li>\n",
    "    <li>Limits of fundamental physics/matter (nanoCMOS)</li>\n",
    "</ul>\n",
    "<li>Horizontal Computing Scaling</li>\n",
    "<ul>\n",
    "    <li>Have more processors</li>\n",
    "    <li>Limits of fundamental physics/matter (nanoCMOS)</li>\n",
    "</ul>\n",
    "<h3>Amdahl's Law</h3>\n",
    "$S=\\frac{1}{\\alpha +(1-\\alpha)/N}$<br>\n",
    "<b>It also assumes a fixed problem size– sometimes can’t predict length of time required for jobs,</b><br>\n",
    "<h3>Gustafson-Barsis's Law</h3>\n",
    "$S(N)=\\alpha +N(1-\\alpha)=N-\\alpha(N-1)$<br>\n",
    "<h3>Flynn's Taxonomy</h3>\n",
    "<li>Single Instruction, Single Data stream (SISD)</li>\n",
    "<ul><li>Basic idea of von Neumann computer</li></ul>\n",
    "<li>Single Instruction, Multiple Data streams (SIMD)</li>\n",
    "<ul><li>Parallel computing architecture where many functional units (PU/CPU) perform different operations on the same data</li>\n",
    "<li>Examples include fault tolerant computer architectures, e.g. running multiple error checking processes on same data stream</li></ul>\n",
    "<li>Multiple Instruction, Single Data stream (MISD)</li>\n",
    "<ul><li>focus is on data level parallelism, i.e. many parallel computations, but only a single process (instruction) at a given moment</li>\n",
    "<li>Many modern computers use SIMD instructions, e.g. to improve performance of multimedia use such as for image processing</li></ul>\n",
    "<li>Multiple Instruction, Multiple Data streams (MIMD)</li>\n",
    "<ul><li>machines can be shared memory or distributed memory categories<br>\n",
    "• depends on how MIMD processors access memory\n",
    "<li>Most systems these days operate on MIMD<br>\n",
    "• HPC …</ul></li>\n",
    "<h3>Implicit Parallelism</h3>\n",
    "Supported by parallel languages and parallelizing compilers that take care of identifying parallelism, the scheduling of calculations and the placement of data<br>\n",
    "• Pretty hard to do (more later!)\n",
    "<h3>Explicit Parallelism</h3>\n",
    "<li>In this approach, the programmer is responsible for most of\n",
    "the parallelization effort such as task decomposition,\n",
    "mapping tasks to processors, inter-process communications</li>\n",
    "<li>This approach assumes user is the best judge of how\n",
    "parallelism can be exploited for a particular application (Typically non-trivial to achieve!)</li>\n",
    "<h3>Hardware Parallelisation</h3>\n",
    "<li>Basic CPU</li>\n",
    "<li>Hardware Threading CPU</li>\n",
    "Usually shares arithmetic units. Heavy use of one type of computation can tie up all the available units of the CPU preventing other threads from using them.\n",
    "<li>Multi-Core</li>\n",
    "issue of cache read/write performance and cache coherence.\n",
    "<li>Symmetric Multiprocessing(SMP)</li>\n",
    "Two (or more) identical processors connected to a single, shared main memory, with full access to all I/O devices, controlled by a single OS instance that treats all processors equally.\n",
    "<li>Non-Uniform Memory Access(NUMA)</li>\n",
    "provides speed-up by allowing a processor to access its own local memory faster than non-local memory(!!! decrease inter-processor communication)\n",
    "<h3>Operating System Parallelism Approaches</h3>\n",
    "Most modern multi-core operating systems support different forms of parallelisation<br>\n",
    "<li>Compute parallelism</li>\n",
    "<ul>\n",
    "    <li>Processes</li>\n",
    "    <li>Threads</li>\n",
    "</ul>\n",
    "<li>Data parallelsim</li>\n",
    "<b>Data parallelism is parallelization across multiple processors in parallel computing environments. It focuses on distributing the data across different nodes, which operate on the data in parallel.</b>\n",
    "<ul>\n",
    "    <li>Caching(cache coherency)</li>\n",
    "    <li>OS implies on \"a\" computer</li>\n",
    "</ul>\n",
    "<h3>Software Parallelism Approach</h3>\n",
    "<b>Key issues that need to be tackled:</b><br>\n",
    "<li>Deadlock</li>\n",
    "<li>Livelock</li>\n",
    "<h3>Message Passing Interface</h3>\n",
    "<li>Key MPI functions</li>\n",
    "<ul>\n",
    "<li>MPI_Init :initiate MPI computation</li>\n",
    "<li>MPI_Finalize :terminate computation</li>\n",
    "<li>MPI_COMM_SIZE :determine number of processors</li>\n",
    "<li>MPI_COMM_RANK :determine my process identifier</li>\n",
    "<li>MPI_SEND :send a message</li>\n",
    "<li>MPI_RECV :receive a message</li>\n",
    "<li>MPI_BCAST:distributes data from one process (the root) to all others in a communicator.</li>\n",
    "<li>MPI_REDUCE:combines data from all processes in communicator and returns it to one process.</li>\n",
    "</ul>\n",
    "<h3>Data Parallelism Approaches</h3>\n",
    "<li>Distributed data</li>\n",
    "CAP Throrem - Consistency, Availability , Partition tolerance<br>\n",
    "ACID(Atomic, Consistency, Isolation, Durability) -> <b>BASE(Basically Available系统能够基本运行、一直提供服务, Soft-state系统不要求一直保持强一致状态, Eventual consistency系统需要在某一时刻后达到一致性要求)</b><br>\n",
    "<li>Distributed File System</li>\n",
    "- e.g. Hadoop\n",
    "<h3>Erroneous Assumptions of Distributed System</h3>\n",
    "<ol>\n",
    "<li>The network is reliable</li>按顺序无损到达\n",
    "<li>Latency is zero</li>\n",
    "<li>Bandwidth is infinite</li>\n",
    "<li>The network is secure</li>\n",
    "<li>Topology doesn't change</li>\n",
    "<li>There is one administrator</li>\n",
    "Firewall changes, server reconfigurations, services, access control\n",
    "<li>Transport cost is zero</li>\n",
    "<li>The network is homogeneous</li>\n",
    "<li>Time is ubiquitous</li>\n",
    "TIme is same across all computers in network\n",
    "</ol>\n",
    "<h3>Design stages of parallel programs</h3>\n",
    "<li>Partitioning</li>\n",
    "<li>Communication</li>\n",
    "<li>Agglomeration</li>集聚\n",
    "<li>Mapping / Scheduling</li>\n",
    "<h3>Partition model</h3>\n",
    "<li>Master Worker/Slave Model</li>master分发任务，归并任务\n",
    "<li>Single-Program Multiple-Data</li>每个进程以一样的代码处理不一样的数据\n",
    "<li>Data pipelining</li>Suitable for applications involving multiple stages of execution, that typically operate on large number of data sets.\n",
    "<li>Divide and Conquer</li>Master-worker/taskfarming is like divide and conquer with master doing both split and join operation\n",
    "<li>Speculative Parallelism</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture4: MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MPI Functions</h3>\n",
    "<ul>\n",
    "<li>MPI_Init :initiate MPI computation</li>\n",
    "<li>MPI_Finalize :terminate computation</li>\n",
    "<li>MPI_COMM_SIZE :determine number of processors</li>\n",
    "<li>MPI_COMM_RANK :determine my process identifier</li>\n",
    "<li>MPI_SEND :send a message</li>\n",
    "<li>MPI_RECV :receive a message</li>\n",
    "<li>MPI_BCAST:distributes data from one process (the root) to all others in a communicator.</li>\n",
    "<li>MPI_REDUCE:combines data from all processes in communicator and returns it to one process.</li>\n",
    "</ul>\n",
    "<h3>Supercomputers</h3>\n",
    "it means any single computer system(itself a contested term) that has exceptional processing power for its time.\n",
    "<h3>High Performance Computing</h3>\n",
    "High-performance computing (HPC) is any computer system whose architecture allows for above average performance. A system that is one of the most powerful in\n",
    "the world, but is poorly designed, could be a \"supercomputer\".\n",
    "<h3>Clustered computing</h3>\n",
    "Clustered computing is when two or more computers serve a single resource. This improves performance and provides redundancy; typically a collection of smaller computers strapped together with a high-speed <b>local network</b>.\n",
    "<h3>Parallel computing</h3>\n",
    "Parallel computing refers to the submission of jobs or processes over multiple processors and by splitting up the data or tasks between them.\n",
    "<h3>Research computing</h3>\n",
    "Research computing is the software applications used by a research community to aid research.\n",
    "<h3>Limitations of Parallel Compution</h3>\n",
    "<li>Synchronisation and atomic operations causes loss of performance, communication latency.</li>\n",
    "<h3>Slurms</h3>\n",
    "Simple Linux Utility for Resource Management,now simply called Slurm Workload Manager, also uses batch script where are very similar in intent and style to PBS scripts.<br>\n",
    "Submitting and running jobs is a relatively straight-forward process consisting of:<br>\n",
    "1) Setup and launch<br>\n",
    "2) Job Control, Monitor results<br>\n",
    "3) Retrieve results and analyse<br>\n",
    "<b>Script Example</b><br>\n",
    "#SBATCH --time=01:00:00<br>\n",
    "#SBATCH --nodes=1<br>\n",
    "#SBATCH --ntasks-per-node=1<br>\n",
    "<h3>multithreading</h3>\n",
    "a master thread forks a number of sub-threads and divides tasks between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture5: NeCTAR/Unimelb Cloud & Scripting & Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cloud Computing</h3>\n",
    "Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.<br>\n",
    "<b>Essential Characteristics</b><br>\n",
    "<li>On-demand self-service</li>\n",
    "<li>Broad network access</li>\n",
    "<li>Resource pooling</li>\n",
    "<li>Rapid elasticity</li>\n",
    "<li>Measured service</li>\n",
    "<h3>Cloud Deployment Models</h3>\n",
    "<li><b>Public Cloud</b></li>\n",
    "<ul>\n",
    "<li><b>Pros</b><br>\n",
    "Utility computing<br>\n",
    "Can focus on core business<br>\n",
    "Cost-effective<br>\n",
    "“Right-sizing”<br>\n",
    "Democratisation of computing<br></li>\n",
    "<li><b>Cons</b><br>\n",
    "Security<br>\n",
    "Loss of control<br>\n",
    "Possible lock-in<br>\n",
    "Dependency of Cloud provider continued existence</li>\n",
    "</ul>\n",
    "<li><b>Private Cloud</b></li>\n",
    "<ul>\n",
    "<li><b>Pros</b><br>\n",
    "Control<br>\n",
    "Consolidation of resources<br>\n",
    "Easier to secure<br>\n",
    "More trust<br></li>\n",
    "<li><b>Cons</b><br>\n",
    "Relevance to core business?<br>\n",
    "-----e.g. Netflix moved to Amazon<br>\n",
    "Staff/management overheads<br>\n",
    "Hardware obsolescence<br>\n",
    "Over/under utilisation challenges<br></li>\n",
    "</ul>\n",
    "<li><b>Hybrid Cloud</b></li>\n",
    "<ul>\n",
    "    <li><b>Examples</b></li>\n",
    "    Eucalyptus, VMWare vCloud Hybrid Service\n",
    "<li><b>Pros</b><br>\n",
    "Cloud-bursting<br>\n",
    "Use private cloud, but burst into public cloud when needed\n",
    "</li>\n",
    "<li><b>Cons</b><br>\n",
    "How do you move data/resources when needed?<br>\n",
    "How to decide (in real time?) what data can go to public cloud?<br>\n",
    "Is the public cloud compliant with PCI-DSS (Payment Card Industry – Data Security Standard)?<br></li>\n",
    "</ul>\n",
    "<h3>Delivery Models</h3>\n",
    "<li>SaaS</li>Gmail\n",
    "<li>Paas</li>MIcrosoft Azure/Amazon Elastic Aneka\n",
    "<li>Iaas</li>Nectar\n",
    "<h3>NeCTAR</h3>\n",
    "National eResearch Collaboration Tools and Resources\n",
    "(based on OpenStack)\n",
    "<h3>Automation</h3>\n",
    "Automation is the mechanism used to make servers reach a desirable state, previously defined by provisioning scripts using tool-specific languages and features. \n",
    "<li>Provides a record of what you did</li>\n",
    "<li>Codifies knowledge about the system</li>\n",
    "<li>Makes process repeatable</li>\n",
    "<li>Makes it programmable – “Infrastructure as Code”</li>\n",
    "<h3>Scripting Tools</h3>\n",
    "<li>Cloud-focused</li>\n",
    "Used to interact with Cloud services.\n",
    "<li>Shell script</li>\n",
    "Bash/Perl\n",
    "<li><b>Configuration management (CM) tools</b></li>\n",
    "Configuration management refers to the process of systematically handling changes to a system in a way that it maintains integrity over time.\n",
    "<h3>Ansible</h3>\n",
    "An automation tool for configuring and managing computers\n",
    "<h3>Ansible:Features</h3>\n",
    "<li>Easy to learn</li>\n",
    "<li>Minimal requirements</li>\n",
    "<li>Idempotent</li>\n",
    "<li>Extensible</li>\n",
    "<h3>GIT</h3>\n",
    "<li>merge</li>\n",
    "目标分支改变加到自己分支中\n",
    "<li>rebase</li>\n",
    "回退到共同分支，执行目标分支changes（打到目标分支状态），执行自己分支changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture6.1: Web Services"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Architecture</h3>\n",
    "A (system) architecture, is just the way different software components are distributed on computers, and the way in which they interact with each other.(UML ofen used)\n",
    "<h3>Service-oriented Architecture(SOA)</h3>\n",
    "Distributed components (more properly, systems) have to interact in more loosely-coupled ways. Services are often used for this. Typically combinations and commonality of services can be used to form a Service-oriented Architecture (SoA).\n",
    "<h3>SOA Design Principles</h3>\n",
    "<li>Standardized service contract(标准服务契约)</li>服务遵循一个服务描述\n",
    "<li>Service loose coupling(松耦合)</li>服务之间的依赖最小化\n",
    "<li>Service abstractions(服务抽象)</li>对外部隐藏自己的业务逻辑\n",
    "<li>Service reusability(服务复用)</li>业务逻辑切割成多个服务以实现复用的最大化\n",
    "<li>Service autonomy(服务自治)</li>服务应该有对它们封装的逻辑的控制权\n",
    "<li>Service statelessness(服务无状态)</li>\n",
    "<li>Service discoverability(服务发现)</li>服务可被发现\n",
    "<li>Service composability(服务组合)</li>一些服务将大的问题分割成很多小问题\n",
    "<li>Service granularity(服务粒度)</li>优化提供正确粒度级别\n",
    "<li>Service normalization(服务规范化)</li>\n",
    "<li>Service optimization(服务优化)</li>为特定功能提供服务的高质量服务通常优于通用低质量服务\n",
    "<li>Service relevance(服务相关化)</li>功能以用户认可的粒度级别呈现为有意义的服务\n",
    "<li>Service encapsulation(服务封装)</li>许多服务被合并以在SOA下使用并隐藏其内部工作\n",
    "<li>Service location transparency(服务位置透明性)</li>服务使用者无论其在网络中的实际位置如何，都能够调用服务。\n",
    "<h3>Web Services(WS)</h3>\n",
    "Web services used to implement service-oriented architectures<br>\n",
    "<b>Two main flavours(both use HTTP)</b><br>\n",
    "<li>SOAP-based Web Services</li>\n",
    "<li>Rest-based Web Services</li>\n",
    "<h3>SOAP/WS vs ReST</h3>\n",
    "<li type=\"circle\">Two patterns to call services over HTTP </li>\n",
    "<li>SOAP/WS is built upon the Remote Procedure Call paradigm; \n",
    "a language independent function call that spans another system </li>\n",
    "<li>ReST is centered around resources, and the way they can be manipulated (added, deleted, etc.) remotely (More from Farzad later) </li>\n",
    "<li>Actually ReST is more of a style to use HTTP than a separate protocol </li>\n",
    "<li>...while SOAP/WS is a stack of protocols that covers every aspect of using a remote service, from service discovery, to service description, to the actual request/response</li>\n",
    "<h3>WSDL</h3>\n",
    "The Web Services Description Language (WSDL) is an XML-based interface description language that describes the functionality offered by a web service.<br>\n",
    "<b>machine-readable:机器可读(不同语言环境适应性)</b><br>\n",
    "<h3>WSDL vs SOAP vs ReST</h3>\n",
    "<li>A WSDL is an XML document that describes a web service. It actually stants for Web Services Description Language.\n",
    "<li>SOAP is an XML-based protocol that lets you exchange into over a particular protocol(can be HTTP or SMTP, for example) between applications. It stands for Simple Object Access Protocol and uses XML for its messaging format to relay the information.\n",
    "<li>REST is an architectural style of networked system and stands for Representational State Transfer. It's not a standard itself, but does use standards such as HTTP,URL,XML,etc.\n",
    "<h3>UDDI</h3>\n",
    "<i>Uniform Description, Discovery and Integration</i> is a protocol to access a registry of services.(用于描述、发现、集成Web Service的技术,通过UDDI，企业可以根据自己的需要动态查找并使用Web服务，也可以将自己的Web服务动态地发布到UDDI注册中心，供其他用户使用。)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 6.2 RESTful Web Services and ROA Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ReST</h3>\n",
    "\"Representational State Transfer (ReST) is intended to evoke an image of how a well-designed Web application behaves\n",
    "<h3>ROA</h3>\n",
    "A ROA is a way of turning a problem into a RESTful web service\n",
    "<li>PUT should be used when target resource url is known by the client</li>\n",
    "<li>POST should be used when target resource URL is server generated.</li>\n",
    "<h3>ReST Principles</h3>\n",
    "<li>Addressability</li>\n",
    "<li>Uniform Interface</li>\n",
    "<ul>\n",
    "<li>Identification of Resources</li>\n",
    "<li>Manipulation of Resources though representations</li>\n",
    "<li>Self-descriptive messages</li>\n",
    "<li>HATEOAS</li>\n",
    "    <ul>\n",
    "        <li>Resource representations contain links to identified resources</li>\n",
    "        <li>Resources and state can be used by navigating links</li>\n",
    "        <li>RESTful applications navigate instead of calling</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "<li>Resources and Representations instrad of RPC</li>\n",
    "<li>HATEOAS(hypermedia as the engine of application states)</li>\n",
    "<h3>HTTP Methods</h3>\n",
    "<li><b>Safe</b></li> -- GET OPTIONS HEAD\n",
    "<li><b>Idempotent</b></li> -- PUT DELETE\n",
    "<li><b>Neither</b></li> -- POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 6.3: Containerisation and Docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Virtualization vs Containerization</h3>\n",
    "<li>Virtualization</li>\n",
    "In computing, virtualization refers to the act of creating a virtual (rather than actual) version of something, including virtual computer hardware platforms, storage devices, and computer network resources.\n",
    "<ul>\n",
    "    <li>Application containment</li>\n",
    "    <li>Horizontal scalability</li>\n",
    "    <li type=\"circle\">resources cost</li>\n",
    "    <li type=\"circle\">Duplications between VMs wasting processors, memory and disk space</li>\n",
    "    <li type=\"circle\">Limiting the number of VMs each server</li>\n",
    "</ul>\n",
    "<li>Containerization</li>\n",
    "<ul>\n",
    "    <li>Share single host OS to reduce wasted resources</li>\n",
    "</ul>\n",
    "<img src=\"./img/L6-1.png\" width=\"500\" height=\"400\"/>\n",
    "<h3>Virtual Machine</h3>\n",
    "In computing, a virtual machine (VM) is an emulation(仿真) of a computer system. Virtual machines are based on computer architectures and provide functionality of a physical computer.\n",
    "<h3>Container</h3>\n",
    "Similar concept of resource isolation and allocation as a virtual machine.\n",
    "<h3>Container Orchestration Tools</h3>\n",
    "Container orchestration technologies provides a framework for integrating and managing containers at scale.(Kubernates/Docker SWARM/Others)<br>\n",
    "<b>Goals:</b><br>\n",
    "<li>Simplify container management processes</li>\n",
    "<li>Help to manage availability and scaling of containers</li>\n",
    "<h3>Docker Networking Mode</h3>\n",
    "<li>host</li>共享host ip，不同port\n",
    "<li>bridge</li>不同ip\n",
    "<h3>Docker SWARM</h3>\n",
    "<li>一个container执行一个task</li>\n",
    "<li>一个或多个task组成一个service</li>\n",
    "<li>manage nodes有一个leader，由raft选举</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
